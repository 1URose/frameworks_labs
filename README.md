# Студент группы М80-407Б-22 Ермаков Ярослав

# Лабораторная работа №1 — алгоритм k ближайших соседей (KNN)

#### Регрессия:
| Модель                               | MSE       | MAE      | R^2    |
| ------------------------------------ | --------- | -------- | ----- |
| Sklearn (до улучшения)               | 2.316e+08 |  10754   | 0.903 |
| Sklearn (после улучшения)            | 2.406e+08 |   9407   | 0.900 |
| Собственная модель (до улучшения)    | 2.408e+08 |  10642   | 0.900 |
| Собственная модель (после улучшения) | 2.414e+08 |   9374   | 0.899 |

#### Классификация:

| Модель                               | Accuracy  | Precision | Recall | F1-score |
| ------------------------------------ | --------- | --------- | ------ | -------- |
| Sklearn (до улучшения)               |    0.739  |    0.737  | 0.739  | 0.737    |
| Sklearn (после улучшения)            |    0.825  |    0.825  | 0.825  | 0.823    |
| Собственная модель (до улучшения)    |    0.739  |    0.737  | 0.739  | 0.737    |
| Собственная модель (после улучшения) |    0.825  |    0.825  | 0.825  | 0.823    |

# Лабораторная работа 2 (Linear Model)

#### Регрессия:

| Модель                                   |      MSE |      MAE |   R^2  |
| :--------------------------------------- | -------: | -------: | :---: |
| Sklearn (до улучшения)                   | 2.33e+08 | 10613.91 | 0.903 |
| Sklearn (после улучшения)                | 2.27e+08 | 10488.54 | 0.905 |
| Собственная имплементация (до улучшения) | 2.33e+08 | 10613.91 | 0.903 |
| Собственная имплементация (после улучш.) | 2.32e+08 | 10616.83 | 0.903 |

#### Классификация:

| Модель                                   | Accuracy | Precision | Recall | F1-score |
| :--------------------------------------- | -------: | --------: | -----: | -------: |
| Sklearn (до улучшения)                   |   84.29% |    84.23% | 84.29% |   84.24% |
| Sklearn (после улучшения)                |   84.50% |    84.45% | 84.50% |   84.46% |
| Собственная имплементация (до улучшения) |   76.76% |    80.38% | 76.76% |   76.84% |
| Собственная имплементация (после улучш.) |   82.31% |    82.35% | 82.31% |   82.10% |


# Лабораторная работа 3 (DecisionTree)

#### Регрессия:


| Модель                               |    MSE   |    MAE   | R^2 |
| :----------------------------------- | :------: | :------: | :---: |
| Sklearn (до улучшения)               | 2.31e+08 |  9428.57 | 0.904 |
| Sklearn (после улучшения)            | 3.19e+08 | 10917.80 | 0.867 |
| Собственная модель (до улучшения)    | 2.60e+08 |  9961.90 | 0.891 |
| Собственная модель (после улучшения) | 3.29e+08 | 11228.91 | 0.863 |

#### Классификация:

| Модель                               | Accuracy | Precision | Recall | F1-score |
| :----------------------------------- | -------: | --------: | -----: | -------: |
| Sklearn (до улучшения)               |   76.44% |    76.49% | 76.44% |   76.46% |
| Sklearn (после улучшения)            |   82.06% |    81.99% | 82.06% |   81.99% |
| Собственная модель (до улучшения)    |   76.80% |    76.80% | 76.80% |   76.80% |
| Собственная модель (после улучшения) |   82.06% |    81.99% | 82.06% |   81.99% |

# Лабораторная работа 4 (RandomForest)

#### Регрессия:

| Модель                               |    MSE   |    MAE   | R^2 |
| :----------------------------------- | :------: | :------: | :---: |
| Sklearn (до улучшения)               | 3.09e+08 | 11791.29 | 0.871 |
| Sklearn (после улучшения)            | 2.26e+08 |  9620.51 | 0.906 |
| Собственная модель (до улучшения)    | 2.88e+08 | 11644.18 | 0.880 |
| Собственная модель (после улучшения) | 2.26e+08 | 9620.51  | 0.906 |

#### Классификация:

| Модель                               | Accuracy | Precision | Recall | F1-score |
| :----------------------------------- | -------: | --------: | -----: | -------: |
| Sklearn (до улучшения)               |   81.87% |    81.93% | 81.87% |   81.62% |
| Sklearn (после улучшения)            |   83.46% |    83.49% | 83.46% |   83.29% |
| Собственная модель (до улучшения)    |   79.11% |    81.85% | 79.11% |   77.78% |
| Собственная модель (после улучшения) |   83.89% |    83.84% | 83.89% |   83.84% |

# Лабораторная работа 5 (Gradient Boosting)

#### Регрессия:

| Модель                                      |      MSE |      MAE | R^2 |
| :------------------------------------------ | -------: | -------: | :---: |
| Sklearn (до улучшения)                      | 2.48e+08 |  9997.82 | 0.897 |
| Sklearn (после улучшения)                   | 2.20e+08 |  9084.95 | 0.908 |
| Собственная имплементация (до улучшения)    | 2.33e+08 | 10172.64 | 0.903 |
| Собственная имплементация (после улучшения) | 2.14e+08 |  9058.04 | 0.911 |

#### Классификация:

| Модель                                      | Accuracy | Precision | Recall | F1-score |
| :------------------------------------------ | -------: | --------: | -----: | -------: |
| Sklearn (до улучшения)                      |   82.85% |    82.79% | 82.85% |   82.80% |
| Sklearn (после улучшения)                   |   84.29% |    84.23% | 84.29% |   84.23% |
| Собственная имплементация (до улучшения)    |   82.40% |    83.08% | 82.40% |   82.52% |
| Собственная имплементация (после улучшения) |   82.89% |    83.76% | 82.89% |   83.01% |


## Выводы

* Готовые модели из `sklearn` почти всегда дают очень сильный старт, но если аккуратно настроить свои версии (как в `Random Forest` и `Gradient Boosting`), то они тоже могут показывать такое же или даже лучшее качество.
* В регрессии лучше всего работают ансамбли — особенно `Gradient Boosting`, чуть слабее, но тоже уверенно ведёт себя `Random Forest`; `KNN` и линейная модель дают хороший, но более простой уровень.
* В классификации самыми надёжными оказались `Linear Model`, `Random Forest` и `Gradient Boosting`, они дают самые высокие Accuracy и F1-score.
* Настройка гиперпараметров, выбор нормальной кодировки категориальных признаков и масштабирование числовых признаков почти всегда помогают, но иногда слишком сложная модель (например, слишком глубокое дерево) начинает переобучаться и ухудшает результат.
