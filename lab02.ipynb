{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2 (Linear Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт всех необходимых модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet\n",
    "\n",
    "\n",
    "def regression_cross_validate(model_cls, X, y, n_folds: int = 5, **model_kwargs):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    mae_values = []\n",
    "    mse_values = []\n",
    "    r2_values = []\n",
    "\n",
    "    for fold_idx, (idx_train, idx_valid) in enumerate(kf.split(X), start=1):\n",
    "        X_train, X_valid = X[idx_train], X[idx_valid]\n",
    "        y_train, y_valid = y[idx_train], y[idx_valid]\n",
    "\n",
    "        model = model_cls(**model_kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_valid)\n",
    "\n",
    "        mae_values.append(mean_absolute_error(y_valid, y_pred))\n",
    "        mse_values.append(mean_squared_error(y_valid, y_pred))\n",
    "        r2_values.append(r2_score(y_valid, y_pred))\n",
    "\n",
    "    metrics_avg = {\n",
    "        \"MAE\": float(np.mean(mae_values)),\n",
    "        \"MSE\": float(np.mean(mse_values)),\n",
    "        \"R2\": float(np.mean(r2_values)),\n",
    "    }\n",
    "\n",
    "    metrics_std = {\n",
    "        \"MAE\": float(np.std(mae_values)),\n",
    "        \"MSE\": float(np.std(mse_values)),\n",
    "        \"R2\": float(np.std(r2_values)),\n",
    "    }\n",
    "\n",
    "    return metrics_avg, metrics_std\n",
    "\n",
    "\n",
    "def classification_cross_validate(model_cls, X, y, n_folds: int = 5, **model_kwargs):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    acc_list = []\n",
    "    prec_list = []\n",
    "    rec_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for fold_idx, (idx_train, idx_valid) in enumerate(kf.split(X), start=1):\n",
    "        X_train, X_valid = X[idx_train], X[idx_valid]\n",
    "        y_train, y_valid = y[idx_train], y[idx_valid]\n",
    "\n",
    "        model = model_cls(**model_kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_valid)\n",
    "\n",
    "        acc_list.append(accuracy_score(y_valid, y_pred))\n",
    "        prec_list.append(precision_score(y_valid, y_pred, average=\"weighted\", zero_division=0))\n",
    "        rec_list.append(recall_score(y_valid, y_pred, average=\"weighted\", zero_division=0))\n",
    "        f1_list.append(f1_score(y_valid, y_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "    metrics_avg = {\n",
    "        \"Accuracy\": float(np.mean(acc_list)),\n",
    "        \"Precision\": float(np.mean(prec_list)),\n",
    "        \"Recall\": float(np.mean(rec_list)),\n",
    "        \"F1-score\": float(np.mean(f1_list)),\n",
    "    }\n",
    "\n",
    "    metrics_std = {\n",
    "        \"Accuracy\": float(np.std(acc_list)),\n",
    "        \"Precision\": float(np.std(prec_list)),\n",
    "        \"Recall\": float(np.std(rec_list)),\n",
    "        \"F1-score\": float(np.std(f1_list)),\n",
    "    }\n",
    "\n",
    "    return metrics_avg, metrics_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Регрессия\n",
    "Данные о зарплатах загружаются в DataFrame, и выводятся первые строки, чтобы убедиться, что файл прочитан корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета Salary_Data: (375, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Years of Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Director</td>\n",
       "      <td>20.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender Education Level          Job Title  Years of Experience  \\\n",
       "0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
       "1  28.0  Female        Master's       Data Analyst                  3.0   \n",
       "2  45.0    Male             PhD     Senior Manager                 15.0   \n",
       "3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
       "4  52.0    Male        Master's           Director                 20.0   \n",
       "\n",
       "     Salary  \n",
       "0   90000.0  \n",
       "1   65000.0  \n",
       "2  150000.0  \n",
       "3   60000.0  \n",
       "4  200000.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df = pd.read_csv(\"data/Salary Data.csv\")\n",
    "print(\"Размер датасета Salary_Data:\", salary_df.shape)\n",
    "\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для регрессии\n",
    "\n",
    "Сначала из датасета убирается столбец `Job Title`: он содержит много уникальных значений и в таком виде мало помогает линейной модели, только раздувает пространство признаков\n",
    "\n",
    "Категориальные признаки (`Gender`, `Education Level`) переводятся в числовой вид с помощью `OrdinalEncoder`, чтобы их можно было использовать в линейной регрессии и в собственной реализации модели\n",
    "\n",
    "После этого все пропуски в данных заполняются наиболее частыми значениями (`SimpleImputer` с стратегией `\"most_frequent\"`). Такой шаг нужен, потому что большинство моделей из `sklearn`, а также наши собственные реализации, не умеют работать с `NaN` и ожидают полностью числовую матрицу признаков без пропусков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN в X_train_base: 0\n",
      "NaN в X_test_base: 0\n"
     ]
    }
   ],
   "source": [
    "reg_df = salary_df.copy()\n",
    "reg_df = reg_df.dropna(subset=[\"Salary\"])\n",
    "\n",
    "if \"Job Title\" in reg_df.columns:\n",
    "    reg_df = reg_df.drop(columns=[\"Job Title\"])\n",
    "\n",
    "X_reg = reg_df.drop(columns=[\"Salary\"])\n",
    "y_reg = reg_df[\"Salary\"]\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "reg_categorical_cols = [\"Gender\", \"Education Level\"]\n",
    "reg_numeric_cols = [col for col in X_reg.columns if col not in reg_categorical_cols]\n",
    "\n",
    "reg_ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "X_reg_train_base = X_reg_train.copy()\n",
    "X_reg_test_base = X_reg_test.copy()\n",
    "\n",
    "X_reg_train_base[reg_categorical_cols] = reg_ordinal_encoder.fit_transform(\n",
    "    X_reg_train_base[reg_categorical_cols]\n",
    ")\n",
    "X_reg_test_base[reg_categorical_cols] = reg_ordinal_encoder.transform(\n",
    "    X_reg_test_base[reg_categorical_cols]\n",
    ")\n",
    "\n",
    "reg_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "X_reg_train_base = pd.DataFrame(\n",
    "    reg_imputer.fit_transform(X_reg_train_base),\n",
    "    columns=X_reg_train_base.columns\n",
    ")\n",
    "X_reg_test_base = pd.DataFrame(\n",
    "    reg_imputer.transform(X_reg_test_base),\n",
    "    columns=X_reg_test_base.columns\n",
    ")\n",
    "\n",
    "print(\"NaN в X_train_base:\", X_reg_train_base.isna().sum().sum())\n",
    "print(\"NaN в X_test_base:\", X_reg_test_base.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала через кросс-валидацию на обучающей выборке считаются средние значения метрик, чтобы получить устойчивую оценку качества. Затем та же модель обучается на всём train-наборе, тестируется на отложенных данных и выводятся метрики на test-выборке для сравнения с последующими улучшенными вариантами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: бейзлайн (train CV) ===\n",
      "MSE_mean: 239121094.97\n",
      "MAE_mean: 11692.15\n",
      "R2_mean:  0.896\n",
      "\n",
      "Регрессия - бейзлайн (test)\n",
      "---------------------------\n",
      "MSE: 232595028.53\n",
      "MAE: 10613.91\n",
      "R^2: 0.903\n"
     ]
    }
   ],
   "source": [
    "reg_cv_mean, reg_cv_std = regression_cross_validate(\n",
    "    LinearRegression,\n",
    "    X_reg_train_base.to_numpy(),\n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    ")\n",
    "\n",
    "linreg_baseline = LinearRegression()\n",
    "linreg_baseline.fit(X_reg_train_base, y_reg_train)\n",
    "\n",
    "y_reg_pred_test = linreg_baseline.predict(X_reg_test_base)\n",
    "\n",
    "test_mse = mean_squared_error(y_reg_test, y_reg_pred_test)\n",
    "test_mae = mean_absolute_error(y_reg_test, y_reg_pred_test)\n",
    "test_r2 = r2_score(y_reg_test, y_reg_pred_test)\n",
    "\n",
    "print(\"=== Регрессия: бейзлайн (train CV) ===\")\n",
    "print(f\"MSE_mean: {reg_cv_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {reg_cv_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {reg_cv_mean['R2']:.3f}\")\n",
    "\n",
    "print(\"\\nРегрессия - бейзлайн (test)\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"MSE: {test_mse:.2f}\")\n",
    "print(f\"MAE: {test_mae:.2f}\")\n",
    "print(f\"R^2: {test_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшенный бейзлайн для регрессии\n",
    "\n",
    "Дальше пробуем усилить модель за счёт более аккуратной обработки признаков. Для категориальных столбцов (`Gender`, `Education Level`) вместо простого численного кодирования используется `OneHotEncoder`, который разворачивает их в набор бинарных признаков . Числовые признаки (`Age`, `Years of Experience`) дополнительно приводятся к одному масштабу с помощью `StandardScaler`, чтобы ни один из них не доминировал за счёт больших значений: на выходе получаем обновлённую обучающую и тестовую матрицы (`X_reg_train_scaled`, `X_reg_test_scaled`), которые дальше используются в улучшенном варианте модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_onehot = OneHotEncoder(\n",
    "    sparse_output=False,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "reg_categorical_cols = [\"Gender\", \"Education Level\"]\n",
    "reg_numeric_cols = [col for col in X_reg.columns if col not in reg_categorical_cols]\n",
    "\n",
    "train_cat_ohe = reg_onehot.fit_transform(X_reg_train[reg_categorical_cols])\n",
    "test_cat_ohe = reg_onehot.transform(X_reg_test[reg_categorical_cols])\n",
    "\n",
    "ohe_reg_cols = reg_onehot.get_feature_names_out(reg_categorical_cols)\n",
    "\n",
    "X_reg_train_ohe = pd.concat(\n",
    "    [\n",
    "        X_reg_train[reg_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(train_cat_ohe, columns=ohe_reg_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "X_reg_test_ohe = pd.concat(\n",
    "    [\n",
    "        X_reg_test[reg_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(test_cat_ohe, columns=ohe_reg_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "reg_scaler = StandardScaler()\n",
    "X_reg_train_scaled = X_reg_train_ohe.copy()\n",
    "X_reg_test_scaled = X_reg_test_ohe.copy()\n",
    "\n",
    "X_reg_train_scaled[reg_numeric_cols] = reg_scaler.fit_transform(\n",
    "    X_reg_train_ohe[reg_numeric_cols]\n",
    ")\n",
    "X_reg_test_scaled[reg_numeric_cols] = reg_scaler.transform(\n",
    "    X_reg_test_ohe[reg_numeric_cols]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на кросс-валидации считается качество модели ElasticNet, обученной на one-hot + отмасштабированных признаках. Затем та же модель дообучается на всей обучающей выборке, тестируется на отложенных данных, и по MSE/MAE/R^2 можно сравнить, насколько регуляризация и улучшенный препроцессинг помогают по сравнению с простой линейной регрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: улучшенный бейзлайн (train CV) ===\n",
      "MSE_mean: 233219582.60\n",
      "MAE_mean: 11262.21\n",
      "R2_mean:  0.898\n",
      "\n",
      "Регрессия - улучшенный бейзлайн (test)\n",
      "--------------------------------------\n",
      "MSE: 227094653.11\n",
      "MAE: 10488.54\n",
      "R^2: 0.905\n"
     ]
    }
   ],
   "source": [
    "reg_enet_cv_mean, reg_enet_cv_std = regression_cross_validate(\n",
    "    ElasticNet,\n",
    "    X_reg_train_scaled.to_numpy(),\n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    alpha=0.01,\n",
    "    l1_ratio=0.7,\n",
    ")\n",
    "\n",
    "print(\"=== Регрессия: улучшенный бейзлайн (train CV) ===\")\n",
    "print(f\"MSE_mean: {reg_enet_cv_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {reg_enet_cv_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {reg_enet_cv_mean['R2']:.3f}\")\n",
    "\n",
    "enet_model = ElasticNet(alpha=0.01, l1_ratio=0.7)\n",
    "enet_model.fit(X_reg_train_scaled, y_reg_train)\n",
    "\n",
    "y_reg_pred_enet = enet_model.predict(X_reg_test_scaled)\n",
    "\n",
    "mse_enet = mean_squared_error(y_reg_test, y_reg_pred_enet)\n",
    "mae_enet = mean_absolute_error(y_reg_test, y_reg_pred_enet)\n",
    "r2_enet = r2_score(y_reg_test, y_reg_pred_enet)\n",
    "\n",
    "print(\"\\nРегрессия - улучшенный бейзлайн (test)\")\n",
    "print(\"--------------------------------------\")\n",
    "print(f\"MSE: {mse_enet:.2f}\")\n",
    "print(f\"MAE: {mae_enet:.2f}\")\n",
    "print(f\"R^2: {r2_enet:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация своего класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом классе реализована упрощённая версия модели с регуляризацией ElasticNet: сначала к признакам добавляется столбец единиц, и параметры линейной регрессии оцениваются через нормальное уравнение. Затем к найденным весам добавляется смесь L1- и L2-штрафов, после чего регуляризованные коэффициенты и интерсепт сохраняются в `self.coef_` и `self.intercept_`, а метод `predict` использует их для вычисления линейного прогноза\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyElasticNet:\n",
    "    def __init__(self, alpha=1.0, l1_ratio=0.5, max_iter=1000, tol=1e-4):\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "        self.coef_ = None      \n",
    "        self.intercept_ = None \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        design_matrix = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        theta = np.linalg.pinv(design_matrix.T @ design_matrix) @ design_matrix.T @ y\n",
    "\n",
    "        intercept = theta[0]\n",
    "        weights = theta[1:]\n",
    "\n",
    "        l1_penalty = self.alpha * self.l1_ratio * np.sign(weights)\n",
    "        l2_penalty = self.alpha * (1.0 - self.l1_ratio) * weights\n",
    "\n",
    "        weights = weights - (l1_penalty + l2_penalty)\n",
    "\n",
    "        self.intercept_ = intercept\n",
    "        self.coef_ = weights\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return X @ self.coef_ + self.intercept_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cначала через кросс-валидацию без регуляризации (alpha=0, l1_ratio=0) оцениваются средние метрики на обучающей выборке. Затем та же модель обучается на базовых признаках и проверяется на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: собственная модель (train CV, без улучшений) ===\n",
      "MSE_mean: 239121094.97\n",
      "MAE_mean: 11692.15\n",
      "R2_mean:  0.896\n",
      "\n",
      "Регрессия - собственная реализация (test, без улучшений)\n",
      "--------------------------------------------------------\n",
      "MSE: 232595028.53\n",
      "MAE: 10613.91\n",
      "R^2: 0.903\n"
     ]
    }
   ],
   "source": [
    "reg_my_base_mean, reg_my_base_std = regression_cross_validate(\n",
    "    MyElasticNet,\n",
    "    X_reg_train_base.to_numpy(), \n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    alpha=0.0,\n",
    "    l1_ratio=0.0,\n",
    ")\n",
    "\n",
    "print(\"=== Регрессия: собственная модель (train CV, без улучшений) ===\")\n",
    "print(f\"MSE_mean: {reg_my_base_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {reg_my_base_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {reg_my_base_mean['R2']:.3f}\")\n",
    "\n",
    "my_enet_base = MyElasticNet(alpha=0.0, l1_ratio=0.0)\n",
    "my_enet_base.fit(X_reg_train_base, y_reg_train)\n",
    "\n",
    "y_reg_pred_my_base = my_enet_base.predict(X_reg_test_base)\n",
    "\n",
    "mse_my_base = mean_squared_error(y_reg_test, y_reg_pred_my_base)\n",
    "mae_my_base = mean_absolute_error(y_reg_test, y_reg_pred_my_base)\n",
    "r2_my_base = r2_score(y_reg_test, y_reg_pred_my_base)\n",
    "\n",
    "print(\"\\nРегрессия - собственная реализация (test, без улучшений)\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"MSE: {mse_my_base:.2f}\")\n",
    "print(f\"MAE: {mae_my_base:.2f}\")\n",
    "print(f\"R^2: {r2_my_base:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MyElasticNet обучается на one-hot + отмасштабированных признаках с ненулевой регуляризацией, а качество сначала измеряется по кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: собственная реализация (train CV, с улучшениями) ===\n",
      "MSE_mean: 233135666.22\n",
      "MAE_mean: 11303.02\n",
      "R2_mean:  0.898\n",
      "\n",
      "Регрессия — собственная реализация (test, с улучшениями)\n",
      "--------------------------------------------------------\n",
      "MSE: 232347419.73\n",
      "MAE: 10616.83\n",
      "R^2: 0.903\n"
     ]
    }
   ],
   "source": [
    "reg_my_imp_mean, reg_my_imp_std = regression_cross_validate(\n",
    "    MyElasticNet,\n",
    "    X_reg_train_scaled.to_numpy(),\n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    alpha=0.01,\n",
    "    l1_ratio=0.7,\n",
    ")\n",
    "\n",
    "print(\"=== Регрессия: собственная реализация (train CV, с улучшениями) ===\")\n",
    "print(f\"MSE_mean: {reg_my_imp_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {reg_my_imp_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {reg_my_imp_mean['R2']:.3f}\")\n",
    "\n",
    "my_enet_improved = MyElasticNet(alpha=0.01, l1_ratio=0.7)\n",
    "my_enet_improved.fit(X_reg_train_scaled, y_reg_train)\n",
    "\n",
    "y_reg_pred_my_imp = my_enet_improved.predict(X_reg_test_scaled)\n",
    "\n",
    "mse_my_imp = mean_squared_error(y_reg_test, y_reg_pred_my_imp)\n",
    "mae_my_imp = mean_absolute_error(y_reg_test, y_reg_pred_my_imp)\n",
    "r2_my_imp = r2_score(y_reg_test, y_reg_pred_my_imp)\n",
    "\n",
    "print(\"\\nРегрессия — собственная реализация (test, с улучшениями)\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"MSE: {mse_my_imp:.2f}\")\n",
    "print(f\"MAE: {mae_my_imp:.2f}\")\n",
    "print(f\"R^2: {r2_my_imp:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Student</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Student</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Srinagar</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BA</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender   Age           City Profession  Academic Pressure  \\\n",
       "0   2    Male  33.0  Visakhapatnam    Student                5.0   \n",
       "1   8  Female  24.0      Bangalore    Student                2.0   \n",
       "2  26    Male  31.0       Srinagar    Student                3.0   \n",
       "3  30  Female  28.0       Varanasi    Student                3.0   \n",
       "4  32  Female  25.0         Jaipur    Student                4.0   \n",
       "\n",
       "   Work Pressure  CGPA  Study Satisfaction  Job Satisfaction  \\\n",
       "0            0.0  8.97                 2.0               0.0   \n",
       "1            0.0  5.90                 5.0               0.0   \n",
       "2            0.0  7.03                 5.0               0.0   \n",
       "3            0.0  5.59                 2.0               0.0   \n",
       "4            0.0  8.13                 3.0               0.0   \n",
       "\n",
       "      Sleep Duration Dietary Habits   Degree  \\\n",
       "0          5-6 hours        Healthy  B.Pharm   \n",
       "1          5-6 hours       Moderate      BSc   \n",
       "2  Less than 5 hours        Healthy       BA   \n",
       "3          7-8 hours       Moderate      BCA   \n",
       "4          5-6 hours       Moderate   M.Tech   \n",
       "\n",
       "  Have you ever had suicidal thoughts ?  Work/Study Hours  Financial Stress  \\\n",
       "0                                   Yes               3.0               1.0   \n",
       "1                                    No               3.0               2.0   \n",
       "2                                    No               9.0               1.0   \n",
       "3                                   Yes               4.0               5.0   \n",
       "4                                   Yes               1.0               1.0   \n",
       "\n",
       "  Family History of Mental Illness  Depression  \n",
       "0                               No           1  \n",
       "1                              Yes           0  \n",
       "2                              Yes           0  \n",
       "3                              Yes           1  \n",
       "4                               No           0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_df = pd.read_csv('data/Student Depression Dataset.csv')\n",
    "stud_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для классификации\n",
    "\n",
    "Сначала из датасета копируется таблица и разделяются признаки и целевая переменная: столбец `Depression` берётся как метка класса, а `id` удаляется как технический идентификатор. Далее выборка разбивается на обучающую и тестовую части с `stratify=y_clf`, чтобы сохранить исходное распределение классов. Отдельно задаются списки категориальных и числовых признаков, после чего все пропуски в данных заполняются наиболее частыми значениями с помощью `SimpleImputer`, чтобы логистическая регрессия и собственная модель могли работать с полной матрицей без `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Class 12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Arch</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>M.Ed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Com</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Patna</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.47</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>B.Com</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender   Age       City Profession Academic Pressure Work Pressure  CGPA  \\\n",
       "0   Male  18.0     Jaipur    Student               4.0           0.0  6.02   \n",
       "1   Male  25.0   Vadodara    Student               3.0           0.0  6.37   \n",
       "2   Male  30.0  Ahmedabad    Student               3.0           0.0  9.24   \n",
       "3   Male  34.0     Bhopal    Student               3.0           0.0  7.37   \n",
       "4   Male  25.0      Patna    Student               3.0           0.0  7.47   \n",
       "\n",
       "  Study Satisfaction Job Satisfaction Sleep Duration Dietary Habits    Degree  \\\n",
       "0                1.0              0.0      7-8 hours       Moderate  Class 12   \n",
       "1                2.0              0.0      7-8 hours       Moderate    B.Arch   \n",
       "2                2.0              0.0      7-8 hours      Unhealthy      M.Ed   \n",
       "3                5.0              0.0      7-8 hours       Moderate     B.Com   \n",
       "4                4.0              0.0      5-6 hours      Unhealthy     B.Com   \n",
       "\n",
       "  Have you ever had suicidal thoughts ? Work/Study Hours Financial Stress  \\\n",
       "0                                   Yes              3.0              5.0   \n",
       "1                                    No              9.0              1.0   \n",
       "2                                   Yes              5.0              5.0   \n",
       "3                                   Yes             12.0              3.0   \n",
       "4                                    No             11.0              5.0   \n",
       "\n",
       "  Family History of Mental Illness  \n",
       "0                               No  \n",
       "1                              Yes  \n",
       "2                              Yes  \n",
       "3                               No  \n",
       "4                               No  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_df = stud_df.copy()\n",
    "\n",
    "X_clf = clf_df.drop(columns=[\"Depression\", \"id\"])\n",
    "y_clf = clf_df[\"Depression\"]\n",
    "\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(\n",
    "    X_clf,\n",
    "    y_clf,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_clf,\n",
    ")\n",
    "\n",
    "clf_categorical_cols = [\n",
    "    \"Gender\",\n",
    "    \"City\",\n",
    "    \"Profession\",\n",
    "    \"Sleep Duration\",\n",
    "    \"Dietary Habits\",\n",
    "    \"Degree\",\n",
    "    \"Have you ever had suicidal thoughts ?\",\n",
    "    \"Family History of Mental Illness\",\n",
    "]\n",
    "\n",
    "clf_numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Academic Pressure\",\n",
    "    \"Work Pressure\",\n",
    "    \"CGPA\",\n",
    "    \"Study Satisfaction\",\n",
    "    \"Job Satisfaction\",\n",
    "    \"Work/Study Hours\",\n",
    "    \"Financial Stress\",\n",
    "]\n",
    "\n",
    "clf_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "X_clf_train_imp = pd.DataFrame(\n",
    "    clf_imputer.fit_transform(X_clf_train),\n",
    "    columns=X_clf_train.columns,\n",
    ")\n",
    "X_clf_test_imp = pd.DataFrame(\n",
    "    clf_imputer.transform(X_clf_test),\n",
    "    columns=X_clf_test.columns,\n",
    ")\n",
    "\n",
    "X_clf_train_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение бейзлайна "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем категориальные признаки через `OrdinalEncoder`, убеждается, что пропусков больше нет, и на этих данных строит бейзлайновую логистическую регрессию: сначала считает средние метрики по кросс-валидации, затем оценивает качество на тестовой выборке\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN в X_clf_train_base: 0\n",
      "NaN в X_clf_test_base: 0\n",
      "\n",
      "=== Классификация: бейзлайн (train CV) ===\n",
      "Accuracy_mean:  0.847\n",
      "Precision_mean:0.846\n",
      "Recall_mean:   0.847\n",
      "F1_mean:       0.846\n",
      "\n",
      "Классификация - бейзлайн (test)\n",
      "--------------------------------\n",
      "1. Accuracy:  84.29%\n",
      "2. Precision: 84.23%\n",
      "3. Recall:    84.29%\n",
      "4. F1-score:  84.24%\n"
     ]
    }
   ],
   "source": [
    "clf_ordinal_encoder = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=99,\n",
    ")\n",
    "\n",
    "X_clf_train_base = X_clf_train_imp.copy()\n",
    "X_clf_test_base = X_clf_test_imp.copy()\n",
    "\n",
    "X_clf_train_base[clf_categorical_cols] = clf_ordinal_encoder.fit_transform(\n",
    "    X_clf_train_base[clf_categorical_cols]\n",
    ")\n",
    "X_clf_test_base[clf_categorical_cols] = clf_ordinal_encoder.transform(\n",
    "    X_clf_test_base[clf_categorical_cols]\n",
    ")\n",
    "\n",
    "print(\"NaN в X_clf_train_base:\", X_clf_train_base.isna().sum().sum())\n",
    "print(\"NaN в X_clf_test_base:\", X_clf_test_base.isna().sum().sum())\n",
    "\n",
    "clf_cv_mean_base, clf_cv_std_base = classification_cross_validate(\n",
    "    LogisticRegression,\n",
    "    X_clf_train_base.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Классификация: бейзлайн (train CV) ===\")\n",
    "print(f\"Accuracy_mean:  {clf_cv_mean_base['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{clf_cv_mean_base['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {clf_cv_mean_base['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {clf_cv_mean_base['F1-score']:.3f}\")\n",
    "\n",
    "\n",
    "clf_baseline_model = LogisticRegression(max_iter=1000)\n",
    "clf_baseline_model.fit(X_clf_train_base, y_clf_train)\n",
    "\n",
    "y_clf_pred_base = clf_baseline_model.predict(X_clf_test_base)\n",
    "\n",
    "acc_base = accuracy_score(y_clf_test, y_clf_pred_base)\n",
    "prec_base = precision_score(y_clf_test, y_clf_pred_base, average=\"weighted\", zero_division=0)\n",
    "rec_base = recall_score(y_clf_test, y_clf_pred_base, average=\"weighted\", zero_division=0)\n",
    "f1_base = f1_score(y_clf_test, y_clf_pred_base, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"\\nКлассификация - бейзлайн (test)\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_base:.2%}\")\n",
    "print(f\"2. Precision: {prec_base:.2%}\")\n",
    "print(f\"3. Recall:    {rec_base:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_base:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формулировка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформулируем несколько идей для улучшения классификатора: закодировать категориальные признаки через `OneHotEncoder`, чтобы не задавать им искусственный порядок, и нормировать числовые столбцы, чтобы все признаки были в сопоставимом масштабе. В этом блоке как раз выполняются one-hot кодирование категориальных признаков и масштабирование числовых, после чего формируются обновлённые матрицы признаков `X_clf_train_upd` и `X_clf_test_upd` для улучшенной логистической регрессии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_onehot = OneHotEncoder(\n",
    "    sparse_output=False,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "train_cat_ohe = clf_onehot.fit_transform(X_clf_train_imp[clf_categorical_cols])\n",
    "test_cat_ohe = clf_onehot.transform(X_clf_test_imp[clf_categorical_cols])\n",
    "\n",
    "ohe_clf_cols = clf_onehot.get_feature_names_out(clf_categorical_cols)\n",
    "\n",
    "X_clf_train_ohe = pd.concat(\n",
    "    [\n",
    "        X_clf_train_imp[clf_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(train_cat_ohe, columns=ohe_clf_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "X_clf_test_ohe = pd.concat(\n",
    "    [\n",
    "        X_clf_test_imp[clf_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(test_cat_ohe, columns=ohe_clf_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "clf_scaler = StandardScaler()\n",
    "X_clf_train_upd = X_clf_train_ohe.copy()\n",
    "X_clf_test_upd = X_clf_test_ohe.copy()\n",
    "\n",
    "X_clf_train_upd[clf_numeric_cols] = clf_scaler.fit_transform(\n",
    "    X_clf_train_ohe[clf_numeric_cols]\n",
    ")\n",
    "X_clf_test_upd[clf_numeric_cols] = clf_scaler.transform(\n",
    "    X_clf_test_ohe[clf_numeric_cols]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем улучшенную логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Классификация: улучшенный бейзлайн (train CV) ===\n",
      "Accuracy_mean:  0.849\n",
      "Precision_mean:0.849\n",
      "Recall_mean:   0.849\n",
      "F1_mean:       0.849\n",
      "\n",
      "Классификация - улучшенный бейзлайн (test)\n",
      "------------------------------------------\n",
      "1. Accuracy:  84.50%\n",
      "2. Precision: 84.45%\n",
      "3. Recall:    84.50%\n",
      "4. F1-score:  84.46%\n"
     ]
    }
   ],
   "source": [
    "clf_cv_mean_imp, clf_cv_std_imp = classification_cross_validate(\n",
    "    LogisticRegression,\n",
    "    X_clf_train_upd.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    C=0.1,\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "print(\"=== Классификация: улучшенный бейзлайн (train CV) ===\")\n",
    "print(f\"Accuracy_mean:  {clf_cv_mean_imp['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{clf_cv_mean_imp['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {clf_cv_mean_imp['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {clf_cv_mean_imp['F1-score']:.3f}\")\n",
    "\n",
    "clf_improved_model = LogisticRegression(C=0.1, max_iter=1000)\n",
    "clf_improved_model.fit(X_clf_train_upd, y_clf_train)\n",
    "\n",
    "y_clf_pred_improved = clf_improved_model.predict(X_clf_test_upd)\n",
    "\n",
    "acc_imp = accuracy_score(y_clf_test, y_clf_pred_improved)\n",
    "prec_imp = precision_score(y_clf_test, y_clf_pred_improved, average=\"weighted\", zero_division=0)\n",
    "rec_imp = recall_score(y_clf_test, y_clf_pred_improved, average=\"weighted\", zero_division=0)\n",
    "f1_imp = f1_score(y_clf_test, y_clf_pred_improved, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"\\nКлассификация - улучшенный бейзлайн (test)\")\n",
    "print(\"------------------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_imp:.2%}\")\n",
    "print(f\"2. Precision: {prec_imp:.2%}\")\n",
    "print(f\"3. Recall:    {rec_imp:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_imp:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация своего класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственная реализация логистической регрессии: в fit модель обучается методом градиентного спуска с возможной L2-регуляризацией через параметр C, а в predict считаются вероятности через сигмоиду и возвращаются бинарные метки по порогу 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "\n",
    "    def __init__(self, C=0.0, learning_rate=0.01, n_iterations=1000):\n",
    "        self.C = C\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "        self.weights: np.ndarray | None = None\n",
    "        self.bias: float | None = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.weights = np.zeros(n_features, dtype=float)\n",
    "        self.bias = 0.0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            logits = X @ self.weights + self.bias\n",
    "            probs = self._sigmoid(logits)\n",
    "\n",
    "            grad_w = (1.0 / n_samples) * (X.T @ (probs - y))\n",
    "            grad_b = (1.0 / n_samples) * np.sum(probs - y)\n",
    "\n",
    "            if self.C != 0:\n",
    "                grad_w += (1.0 / (self.C * n_samples)) * self.weights\n",
    "\n",
    "            self.weights -= self.learning_rate * grad_w\n",
    "            self.bias -= self.learning_rate * grad_b\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        logits = X @ self.weights + self.bias\n",
    "        probs = self._sigmoid(logits)\n",
    "        return (probs >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Классификация: собственная модель (train CV, без улучшений) ===\n",
      "Accuracy_mean:  0.769\n",
      "Precision_mean:0.804\n",
      "Recall_mean:   0.769\n",
      "F1_mean:       0.770\n",
      "\n",
      "Классификация - собственная реализация (test, без улучшений)\n",
      "------------------------------------------------------------\n",
      "1. Accuracy:  76.76%\n",
      "2. Precision: 80.38%\n",
      "3. Recall:    76.76%\n",
      "4. F1-score:  76.84%\n"
     ]
    }
   ],
   "source": [
    "clf_my_base_mean, clf_my_base_std = classification_cross_validate(\n",
    "    MyLogisticRegression,\n",
    "    X_clf_train_base.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    n_iterations=1000,\n",
    ")\n",
    "\n",
    "print(\"=== Классификация: собственная модель (train CV, без улучшений) ===\")\n",
    "print(f\"Accuracy_mean:  {clf_my_base_mean['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{clf_my_base_mean['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {clf_my_base_mean['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {clf_my_base_mean['F1-score']:.3f}\")\n",
    "\n",
    "my_logreg_base = MyLogisticRegression(n_iterations=1000)\n",
    "my_logreg_base.fit(X_clf_train_base.to_numpy(), y_clf_train.to_numpy())\n",
    "\n",
    "y_clf_pred_my_base = my_logreg_base.predict(X_clf_test_base.to_numpy())\n",
    "\n",
    "acc_my_base = accuracy_score(y_clf_test, y_clf_pred_my_base)\n",
    "prec_my_base = precision_score(y_clf_test, y_clf_pred_my_base, average=\"weighted\", zero_division=0)\n",
    "rec_my_base = recall_score(y_clf_test, y_clf_pred_my_base, average=\"weighted\", zero_division=0)\n",
    "f1_my_base = f1_score(y_clf_test, y_clf_pred_my_base, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"\\nКлассификация - собственная реализация (test, без улучшений)\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_my_base:.2%}\")\n",
    "print(f\"2. Precision: {prec_my_base:.2%}\")\n",
    "print(f\"3. Recall:    {rec_my_base:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_my_base:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "по кросс-валидации считаются средние метрики на one-hot + масштабированных признаках с регуляризацией C=0.1, затем та же модель обучается на всём train-наборе и оценивается на тесте, где выводятся итоговые Accuracy, Precision, Recall и F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Классификация: собственная модель (train CV, с улучшениями) ===\n",
      "Accuracy_mean:  0.830\n",
      "Precision_mean:0.830\n",
      "Recall_mean:   0.830\n",
      "F1_mean:       0.828\n",
      "\n",
      "Классификация - собственная реализация (test, с улучшениями)\n",
      "------------------------------------------------------------\n",
      "1. Accuracy:  82.31%\n",
      "2. Precision: 82.35%\n",
      "3. Recall:    82.31%\n",
      "4. F1-score:  82.10%\n"
     ]
    }
   ],
   "source": [
    "clf_my_imp_mean, clf_my_imp_std = classification_cross_validate(\n",
    "    MyLogisticRegression,\n",
    "    X_clf_train_upd.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    C=0.1,\n",
    "    n_iterations=1000,\n",
    ")\n",
    "\n",
    "print(\"=== Классификация: собственная модель (train CV, с улучшениями) ===\")\n",
    "print(f\"Accuracy_mean:  {clf_my_imp_mean['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{clf_my_imp_mean['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {clf_my_imp_mean['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {clf_my_imp_mean['F1-score']:.3f}\")\n",
    "\n",
    "my_logreg_improved = MyLogisticRegression(C=0.1, n_iterations=1000)\n",
    "my_logreg_improved.fit(X_clf_train_upd.to_numpy(), y_clf_train.to_numpy())\n",
    "\n",
    "y_clf_pred_my_imp = my_logreg_improved.predict(X_clf_test_upd.to_numpy())\n",
    "\n",
    "acc_my_imp = accuracy_score(y_clf_test, y_clf_pred_my_imp)\n",
    "prec_my_imp = precision_score(y_clf_test, y_clf_pred_my_imp, average=\"weighted\", zero_division=0)\n",
    "rec_my_imp = recall_score(y_clf_test, y_clf_pred_my_imp, average=\"weighted\", zero_division=0)\n",
    "f1_my_imp = f1_score(y_clf_test, y_clf_pred_my_imp, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"\\nКлассификация - собственная реализация (test, с улучшениями)\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_my_imp:.2%}\")\n",
    "print(f\"2. Precision: {prec_my_imp:.2%}\")\n",
    "print(f\"3. Recall:    {rec_my_imp:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_my_imp:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "Для задачи регрессии линейные модели показывают достаточно высокое качество уже в базовой постановке: `R^2` около **0.90** означает, что модель объясняет примерно 90 % вариации зарплаты. Переход к one-hot кодированию категориальных признаков, масштабированию числовых и использованию `ElasticNet` даёт небольшое, но стабильное улучшение метрик на тесте, однако прирост не радикален - что ожидаемо для относительно небольшого и простой структуры датасета.\n",
    "\n",
    "Собственная реализация `MyElasticNet` по качеству практически не отличается от моделей из `sklearn`: без улучшений она совпадает с линейной регрессией, а с регуляризацией и улучшенным препроцессингом держится на сопоставимом уровне `R^2`, хотя по MSE/MAE чуть уступает эталонной `ElasticNet`.\n",
    "\n",
    "В классификационной задаче логистическая регрессия уже в бейзлайне даёт около **84 %** по всем основным метрикам. Улучшенный вариант (one-hot кодирование + масштабирование + регуляризация) добавляет ещё ~0.2 процентных пункта. Собственная реализация логистической регрессии заметно выигрывает от улучшенного препроцессинга: с сырыми признаками она ощутимо хуже sklearn-версии, но на преобразованных признаках почти догоняет её по качеству.\n",
    "\n",
    "\n",
    "\n",
    "### Сводная таблица по регрессии\n",
    "\n",
    "| Модель                                   |      MSE |      MAE |   R^2  |\n",
    "| :--------------------------------------- | -------: | -------: | :---: |\n",
    "| Sklearn (до улучшения)                   | 2.33e+08 | 10613.91 | 0.903 |\n",
    "| Sklearn (после улучшения)                | 2.27e+08 | 10488.54 | 0.905 |\n",
    "| Собственная имплементация (до улучшения) | 2.33e+08 | 10613.91 | 0.903 |\n",
    "| Собственная имплементация (после улучш.) | 2.32e+08 | 10616.83 | 0.903 |\n",
    "\n",
    "\n",
    "\n",
    "### Сводная таблица по классификации \n",
    "\n",
    "| Модель                                   | Accuracy | Precision | Recall | F1-score |\n",
    "| :--------------------------------------- | -------: | --------: | -----: | -------: |\n",
    "| Sklearn (до улучшения)                   |   84.29% |    84.23% | 84.29% |   84.24% |\n",
    "| Sklearn (после улучшения)                |   84.50% |    84.45% | 84.50% |   84.46% |\n",
    "| Собственная имплементация (до улучшения) |   76.76% |    80.38% | 76.76% |   76.84% |\n",
    "| Собственная имплементация (после улучш.) |   82.31% |    82.35% | 82.31% |   82.10% |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
