{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4 (RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "def regression_cross_validate(model_cls, X, y, n_folds: int = 5, **model_kwargs):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    mae_values = []\n",
    "    mse_values = []\n",
    "    r2_values = []\n",
    "\n",
    "    for fold_idx, (idx_train, idx_valid) in enumerate(kf.split(X), start=1):\n",
    "        X_train, X_valid = X[idx_train], X[idx_valid]\n",
    "        y_train, y_valid = y[idx_train], y[idx_valid]\n",
    "\n",
    "        model = model_cls(**model_kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_valid)\n",
    "\n",
    "        mae_values.append(mean_absolute_error(y_valid, y_pred))\n",
    "        mse_values.append(mean_squared_error(y_valid, y_pred))\n",
    "        r2_values.append(r2_score(y_valid, y_pred))\n",
    "\n",
    "    metrics_avg = {\n",
    "        \"MAE\": float(np.mean(mae_values)),\n",
    "        \"MSE\": float(np.mean(mse_values)),\n",
    "        \"R2\": float(np.mean(r2_values)),\n",
    "    }\n",
    "\n",
    "    metrics_std = {\n",
    "        \"MAE\": float(np.std(mae_values)),\n",
    "        \"MSE\": float(np.std(mse_values)),\n",
    "        \"R2\": float(np.std(r2_values)),\n",
    "    }\n",
    "\n",
    "    return metrics_avg, metrics_std\n",
    "\n",
    "\n",
    "def classification_cross_validate(model_cls, X, y, n_folds: int = 5, **model_kwargs):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    acc_list = []\n",
    "    prec_list = []\n",
    "    rec_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for fold_idx, (idx_train, idx_valid) in enumerate(kf.split(X), start=1):\n",
    "        X_train, X_valid = X[idx_train], X[idx_valid]\n",
    "        y_train, y_valid = y[idx_train], y[idx_valid]\n",
    "\n",
    "        model = model_cls(**model_kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_valid)\n",
    "\n",
    "        acc_list.append(accuracy_score(y_valid, y_pred))\n",
    "        prec_list.append(precision_score(y_valid, y_pred, average=\"weighted\", zero_division=0))\n",
    "        rec_list.append(recall_score(y_valid, y_pred, average=\"weighted\", zero_division=0))\n",
    "        f1_list.append(f1_score(y_valid, y_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "    metrics_avg = {\n",
    "        \"Accuracy\": float(np.mean(acc_list)),\n",
    "        \"Precision\": float(np.mean(prec_list)),\n",
    "        \"Recall\": float(np.mean(rec_list)),\n",
    "        \"F1-score\": float(np.mean(f1_list)),\n",
    "    }\n",
    "\n",
    "    metrics_std = {\n",
    "        \"Accuracy\": float(np.std(acc_list)),\n",
    "        \"Precision\": float(np.std(prec_list)),\n",
    "        \"Recall\": float(np.std(rec_list)),\n",
    "        \"F1-score\": float(np.std(f1_list)),\n",
    "    }\n",
    "\n",
    "    return metrics_avg, metrics_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Регрессия\n",
    "Данные о зарплатах загружаются в DataFrame, и выводятся первые строки, чтобы убедиться, что файл прочитан корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета Salary_Data: (375, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Years of Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Director</td>\n",
       "      <td>20.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender Education Level          Job Title  Years of Experience  \\\n",
       "0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
       "1  28.0  Female        Master's       Data Analyst                  3.0   \n",
       "2  45.0    Male             PhD     Senior Manager                 15.0   \n",
       "3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
       "4  52.0    Male        Master's           Director                 20.0   \n",
       "\n",
       "     Salary  \n",
       "0   90000.0  \n",
       "1   65000.0  \n",
       "2  150000.0  \n",
       "3   60000.0  \n",
       "4  200000.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df = pd.read_csv(\"data/Salary Data.csv\")\n",
    "print(\"Размер датасета Salary_Data:\", salary_df.shape)\n",
    "\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для регрессии\n",
    "\n",
    "Сначала из датасета убирается столбец `Job Title`: он содержит много уникальных значений и в таком виде мало помогает линейной модели, только раздувает пространство признаков\n",
    "\n",
    "Категориальные признаки (`Gender`, `Education Level`) переводятся в числовой вид с помощью `OrdinalEncoder`, чтобы их можно было использовать в линейной регрессии и в собственной реализации модели\n",
    "\n",
    "После этого все пропуски в данных заполняются наиболее частыми значениями (`SimpleImputer` с стратегией `\"most_frequent\"`). Такой шаг нужен, потому что большинство моделей из `sklearn`, а также наши собственные реализации, не умеют работать с `NaN` и ожидают полностью числовую матрицу признаков без пропусков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN в X_train_base: 0\n",
      "NaN в X_test_base: 0\n"
     ]
    }
   ],
   "source": [
    "reg_df = salary_df.copy()\n",
    "reg_df = reg_df.dropna(subset=[\"Salary\"])\n",
    "\n",
    "if \"Job Title\" in reg_df.columns:\n",
    "    reg_df = reg_df.drop(columns=[\"Job Title\"])\n",
    "\n",
    "X_reg = reg_df.drop(columns=[\"Salary\"])\n",
    "y_reg = reg_df[\"Salary\"]\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "reg_categorical_cols = [\"Gender\", \"Education Level\"]\n",
    "reg_numeric_cols = [col for col in X_reg.columns if col not in reg_categorical_cols]\n",
    "\n",
    "reg_ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "X_reg_train_base = X_reg_train.copy()\n",
    "X_reg_test_base = X_reg_test.copy()\n",
    "\n",
    "X_reg_train_base[reg_categorical_cols] = reg_ordinal_encoder.fit_transform(\n",
    "    X_reg_train_base[reg_categorical_cols]\n",
    ")\n",
    "X_reg_test_base[reg_categorical_cols] = reg_ordinal_encoder.transform(\n",
    "    X_reg_test_base[reg_categorical_cols]\n",
    ")\n",
    "\n",
    "reg_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "X_reg_train_base = pd.DataFrame(\n",
    "    reg_imputer.fit_transform(X_reg_train_base),\n",
    "    columns=X_reg_train_base.columns\n",
    ")\n",
    "X_reg_test_base = pd.DataFrame(\n",
    "    reg_imputer.transform(X_reg_test_base),\n",
    "    columns=X_reg_test_base.columns\n",
    ")\n",
    "\n",
    "print(\"NaN в X_train_base:\", X_reg_train_base.isna().sum().sum())\n",
    "print(\"NaN в X_test_base:\", X_reg_test_base.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение бейзлайна "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь строится и оценивается базовый Random Forest для регрессии: сначала через K-fold кросс-валидацию считаются средние метрики на обучающей выборке, затем та же модель обучается на train и оценивается на test по MSE, MAE и R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: Random Forest (бейзлайн, train CV) ===\n",
      "MSE_mean: 265300960.81\n",
      "MAE_mean: 11402.15\n",
      "R2_mean:  0.884\n",
      "\n",
      "Регрессия — Random Forest (бейзлайн, test)\n",
      "------------------------------------------\n",
      "MSE: 308554490.37\n",
      "MAE: 11791.29\n",
      "R^2: 0.871\n"
     ]
    }
   ],
   "source": [
    "rf_cv_mean, rf_cv_std = regression_cross_validate(\n",
    "    RandomForestRegressor,\n",
    "    X_reg_train_base.to_numpy(),\n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    ")\n",
    "\n",
    "print(\"=== Регрессия: Random Forest (бейзлайн, train CV) ===\")\n",
    "print(f\"MSE_mean: {rf_cv_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {rf_cv_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {rf_cv_mean['R2']:.3f}\")\n",
    "\n",
    "rf_baseline = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    ")\n",
    "rf_baseline.fit(X_reg_train_base, y_reg_train)\n",
    "\n",
    "y_reg_pred_rf = rf_baseline.predict(X_reg_test_base)\n",
    "\n",
    "mse_rf = mean_squared_error(y_reg_test, y_reg_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_reg_test, y_reg_pred_rf)\n",
    "r2_rf = r2_score(y_reg_test, y_reg_pred_rf)\n",
    "\n",
    "print(\"\\nРегрессия — Random Forest (бейзлайн, test)\")\n",
    "print(\"------------------------------------------\")\n",
    "print(f\"MSE: {mse_rf:.2f}\")\n",
    "print(f\"MAE: {mae_rf:.2f}\")\n",
    "print(f\"R^2: {r2_rf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь реализуется улучшенный призначный набор для Random Forest: категориальные признаки кодируются через OneHotEncoder, а численные - нормализуются с помощью StandardScaler. Такой препроцессинг помогает модели лучше работать с разнородными признаками и потенциально повышает качество предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_onehot = OneHotEncoder(\n",
    "    sparse_output=False,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "reg_cat_train_ohe = reg_onehot.fit_transform(X_reg_train[reg_categorical_cols])\n",
    "reg_cat_test_ohe = reg_onehot.transform(X_reg_test[reg_categorical_cols])\n",
    "\n",
    "reg_ohe_cols = reg_onehot.get_feature_names_out(reg_categorical_cols)\n",
    "\n",
    "X_reg_train_ohe = pd.concat(\n",
    "    [\n",
    "        X_reg_train[reg_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(reg_cat_train_ohe, columns=reg_ohe_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "X_reg_test_ohe = pd.concat(\n",
    "    [\n",
    "        X_reg_test[reg_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(reg_cat_test_ohe, columns=reg_ohe_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "reg_scaler = StandardScaler()\n",
    "X_reg_train_rf = X_reg_train_ohe.copy()\n",
    "X_reg_test_rf = X_reg_test_ohe.copy()\n",
    "\n",
    "X_reg_train_rf[reg_numeric_cols] = reg_scaler.fit_transform(\n",
    "    X_reg_train_ohe[reg_numeric_cols]\n",
    ")\n",
    "X_reg_test_rf[reg_numeric_cols] = reg_scaler.transform(\n",
    "    X_reg_test_ohe[reg_numeric_cols]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом фрагменте на улучшенных признаках обучается Random Forest с увеличенным числом деревьев и большей глубиной, а качество оценивается с помощью K-fold кросс-валидации. Затем та же модель проверяется на тестовой выборке, и выводятся итоговые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: Random Forest (train CV, улучшенный бейзлайн) ===\n",
      "MSE_mean: 258339916.92\n",
      "MAE_mean: 10756.03\n",
      "R2_mean:  0.886\n",
      "\n",
      "Регрессия — Random Forest (test, улучшенный бейзлайн)\n",
      "------------------------------------------------------\n",
      "MSE: 225846323.13\n",
      "MAE: 9620.51\n",
      "R^2: 0.906\n"
     ]
    }
   ],
   "source": [
    "rf_imp_mean, rf_imp_std = regression_cross_validate(\n",
    "    RandomForestRegressor,\n",
    "    X_reg_train_rf.to_numpy(),\n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    random_state=42,\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    ")\n",
    "\n",
    "print(\"=== Регрессия: Random Forest (train CV, улучшенный бейзлайн) ===\")\n",
    "print(f\"MSE_mean: {rf_imp_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {rf_imp_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {rf_imp_mean['R2']:.3f}\")\n",
    "\n",
    "rf_improved = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_improved.fit(X_reg_train_rf, y_reg_train)\n",
    "\n",
    "y_reg_pred_rf_imp = rf_improved.predict(X_reg_test_rf)\n",
    "\n",
    "mse_rf_imp = mean_squared_error(y_reg_test, y_reg_pred_rf_imp)\n",
    "mae_rf_imp = mean_absolute_error(y_reg_test, y_reg_pred_rf_imp)\n",
    "r2_rf_imp = r2_score(y_reg_test, y_reg_pred_rf_imp)\n",
    "\n",
    "print(\"\\nРегрессия — Random Forest (test, улучшенный бейзлайн)\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"MSE: {mse_rf_imp:.2f}\")\n",
    "print(f\"MAE: {mae_rf_imp:.2f}\")\n",
    "print(f\"R^2: {r2_rf_imp:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация своего класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь реализован упрощённый вариант алгоритма Random Forest: несколько деревьев обучаются на бутстрэп-выборках и затем усредняют свои предсказания. Такой подход снижает переобучение отдельных деревьев и позволяет повысить устойчивость модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRandomForestRegressor:\n",
    "    def __init__(self, n_estimators: int = 100, max_depth: int | None = None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        self.trees = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            X_boot = X[indices]\n",
    "            y_boot = y[indices]\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X_boot, y_boot)\n",
    "\n",
    "            self.trees.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "\n",
    "        all_preds = np.zeros((len(X), self.n_estimators))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            all_preds[:, i] = tree.predict(X)\n",
    "\n",
    "        return all_preds.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь проводится оценка собственной реализации случайного леса с помощью кросс-валидации, после чего модель обучается на тренировочных данных и проверяется на тестовой выборке. Полученные метрики позволяют сравнить качество кастомного алгоритма с реализацией sklearn и проверить устойчивость модел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: собственный RandomForest (train CV, без улучшений) ===\n",
      "MSE_mean: 270138054.37\n",
      "MAE_mean: 11449.13\n",
      "R2_mean:  0.882\n",
      "\n",
      "Регрессия - собственная реализация RandomForest (test, без улучшений)\n",
      "--------------------------------------------------------------------\n",
      "MSE: 309071132.79\n",
      "MAE: 11841.22\n",
      "R^2: 0.871\n"
     ]
    }
   ],
   "source": [
    "rf_my_base_mean, rf_my_base_std = regression_cross_validate(\n",
    "    MyRandomForestRegressor,\n",
    "    X_reg_train_base.to_numpy(),\n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    ")\n",
    "\n",
    "print(\"=== Регрессия: собственный RandomForest (train CV, без улучшений) ===\")\n",
    "print(f\"MSE_mean: {rf_my_base_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {rf_my_base_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {rf_my_base_mean['R2']:.3f}\")\n",
    "\n",
    "my_rf_base = MyRandomForestRegressor(n_estimators=100, max_depth=3)\n",
    "my_rf_base.fit(X_reg_train_base.to_numpy(), y_reg_train.to_numpy())\n",
    "\n",
    "y_reg_pred_my_rf_base = my_rf_base.predict(X_reg_test_base.to_numpy())\n",
    "\n",
    "mse_my_rf_base = mean_squared_error(y_reg_test, y_reg_pred_my_rf_base)\n",
    "mae_my_rf_base = mean_absolute_error(y_reg_test, y_reg_pred_my_rf_base)\n",
    "r2_my_rf_base = r2_score(y_reg_test, y_reg_pred_my_rf_base)\n",
    "\n",
    "print(\"\\nРегрессия - собственная реализация RandomForest (test, без улучшений)\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"MSE: {mse_my_rf_base:.2f}\")\n",
    "print(f\"MAE: {mae_my_rf_base:.2f}\")\n",
    "print(f\"R^2: {r2_my_rf_base:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом фрагменте оценивается улучшенная версия собственной реализации случайного леса: сначала по K-fold кросс-валидации, затем на тестовой выборке. Это позволяет сравнить поведение кастомного алгоритма с RandomForest из sklearn после введения one-hot кодирования, масштабирования и увеличения числа деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Регрессия: Random Forest (train CV, улучшенный бейзлайн) ===\n",
      "MSE_mean: 258339916.92\n",
      "MAE_mean: 10756.03\n",
      "R2_mean:  0.886\n",
      "\n",
      "Регрессия — Random Forest (test, улучшенный бейзлайн)\n",
      "------------------------------------------------------\n",
      "MSE: 225846323.13\n",
      "MAE: 9620.51\n",
      "R^2: 0.906\n"
     ]
    }
   ],
   "source": [
    "rf_imp_mean, rf_imp_std = regression_cross_validate(\n",
    "    RandomForestRegressor,\n",
    "    X_reg_train_rf.to_numpy(),\n",
    "    y_reg_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    random_state=42,\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    ")\n",
    "\n",
    "print(\"=== Регрессия: Random Forest (train CV, улучшенный бейзлайн) ===\")\n",
    "print(f\"MSE_mean: {rf_imp_mean['MSE']:.2f}\")\n",
    "print(f\"MAE_mean: {rf_imp_mean['MAE']:.2f}\")\n",
    "print(f\"R2_mean:  {rf_imp_mean['R2']:.3f}\")\n",
    "\n",
    "rf_improved = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_improved.fit(X_reg_train_rf, y_reg_train)\n",
    "\n",
    "y_reg_pred_rf_imp = rf_improved.predict(X_reg_test_rf)\n",
    "\n",
    "mse_rf_imp = mean_squared_error(y_reg_test, y_reg_pred_rf_imp)\n",
    "mae_rf_imp = mean_absolute_error(y_reg_test, y_reg_pred_rf_imp)\n",
    "r2_rf_imp = r2_score(y_reg_test, y_reg_pred_rf_imp)\n",
    "\n",
    "print(\"\\nРегрессия — Random Forest (test, улучшенный бейзлайн)\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"MSE: {mse_rf_imp:.2f}\")\n",
    "print(f\"MAE: {mae_rf_imp:.2f}\")\n",
    "print(f\"R^2: {r2_rf_imp:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Student</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Student</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Srinagar</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BA</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender   Age           City Profession  Academic Pressure  \\\n",
       "0   2    Male  33.0  Visakhapatnam    Student                5.0   \n",
       "1   8  Female  24.0      Bangalore    Student                2.0   \n",
       "2  26    Male  31.0       Srinagar    Student                3.0   \n",
       "3  30  Female  28.0       Varanasi    Student                3.0   \n",
       "4  32  Female  25.0         Jaipur    Student                4.0   \n",
       "\n",
       "   Work Pressure  CGPA  Study Satisfaction  Job Satisfaction  \\\n",
       "0            0.0  8.97                 2.0               0.0   \n",
       "1            0.0  5.90                 5.0               0.0   \n",
       "2            0.0  7.03                 5.0               0.0   \n",
       "3            0.0  5.59                 2.0               0.0   \n",
       "4            0.0  8.13                 3.0               0.0   \n",
       "\n",
       "      Sleep Duration Dietary Habits   Degree  \\\n",
       "0          5-6 hours        Healthy  B.Pharm   \n",
       "1          5-6 hours       Moderate      BSc   \n",
       "2  Less than 5 hours        Healthy       BA   \n",
       "3          7-8 hours       Moderate      BCA   \n",
       "4          5-6 hours       Moderate   M.Tech   \n",
       "\n",
       "  Have you ever had suicidal thoughts ?  Work/Study Hours  Financial Stress  \\\n",
       "0                                   Yes               3.0               1.0   \n",
       "1                                    No               3.0               2.0   \n",
       "2                                    No               9.0               1.0   \n",
       "3                                   Yes               4.0               5.0   \n",
       "4                                   Yes               1.0               1.0   \n",
       "\n",
       "  Family History of Mental Illness  Depression  \n",
       "0                               No           1  \n",
       "1                              Yes           0  \n",
       "2                              Yes           0  \n",
       "3                              Yes           1  \n",
       "4                               No           0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_df = pd.read_csv('data/Student Depression Dataset.csv')\n",
    "clf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняется разбиение данных по депрессии на обучающую и тестовую выборки с сохранением исходного распределения классов. Затем для всех признаков заполняются пропуски наиболее частыми значениями, чтобы подготовить данные к дальнейшему кодированию и обучению дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df = clf_df.copy()\n",
    "\n",
    "X_clf = clf_df.drop(columns=[\"Depression\", \"id\"])\n",
    "y_clf = clf_df[\"Depression\"]\n",
    "\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(\n",
    "    X_clf,\n",
    "    y_clf,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_clf,\n",
    ")\n",
    "\n",
    "clf_categorical_cols = [\n",
    "    \"Gender\",\n",
    "    \"City\",\n",
    "    \"Profession\",\n",
    "    \"Sleep Duration\",\n",
    "    \"Dietary Habits\",\n",
    "    \"Degree\",\n",
    "    \"Have you ever had suicidal thoughts ?\",\n",
    "    \"Family History of Mental Illness\",\n",
    "]\n",
    "\n",
    "clf_numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Academic Pressure\",\n",
    "    \"Work Pressure\",\n",
    "    \"CGPA\",\n",
    "    \"Study Satisfaction\",\n",
    "    \"Job Satisfaction\",\n",
    "    \"Work/Study Hours\",\n",
    "    \"Financial Stress\",\n",
    "]\n",
    "\n",
    "clf_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "X_clf_train_imp = pd.DataFrame(\n",
    "    clf_imputer.fit_transform(X_clf_train),\n",
    "    columns=X_clf_train.columns,\n",
    ")\n",
    "X_clf_test_imp = pd.DataFrame(\n",
    "    clf_imputer.transform(X_clf_test),\n",
    "    columns=X_clf_test.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение бейзлайна "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь строится базовый вариант Random Forest для задачи классификации: сначала оцениваем средние метрики по k-fold кросс-валидации, затем обучаем модель на train-наборе и считаем итоговые показатели качества на отложенной тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN в X_clf_train_base: 0\n",
      "NaN в X_clf_test_base: 0\n",
      "=== Классификация: Random Forest (train CV, бейзлайн) ===\n",
      "Accuracy_mean:  0.822\n",
      "Precision_mean:0.822\n",
      "Recall_mean:   0.822\n",
      "F1_mean:       0.820\n",
      "\n",
      "Классификация — Random Forest (test, бейзлайн)\n",
      "----------------------------------------------\n",
      "1. Accuracy:  81.87%\n",
      "2. Precision: 81.93%\n",
      "3. Recall:    81.87%\n",
      "4. F1-score:  81.62%\n"
     ]
    }
   ],
   "source": [
    "clf_ordinal_encoder = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=99,\n",
    ")\n",
    "\n",
    "X_clf_train_base = X_clf_train_imp.copy()\n",
    "X_clf_test_base = X_clf_test_imp.copy()\n",
    "\n",
    "X_clf_train_base[clf_categorical_cols] = clf_ordinal_encoder.fit_transform(\n",
    "    X_clf_train_base[clf_categorical_cols]\n",
    ")\n",
    "X_clf_test_base[clf_categorical_cols] = clf_ordinal_encoder.transform(\n",
    "    X_clf_test_base[clf_categorical_cols]\n",
    ")\n",
    "\n",
    "print(\"NaN в X_clf_train_base:\", X_clf_train_base.isna().sum().sum())\n",
    "print(\"NaN в X_clf_test_base:\", X_clf_test_base.isna().sum().sum())\n",
    "\n",
    "rf_clf_base_mean, rf_clf_base_std = classification_cross_validate(\n",
    "    RandomForestClassifier,\n",
    "    X_clf_train_base.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    ")\n",
    "\n",
    "print(\"=== Классификация: Random Forest (train CV, бейзлайн) ===\")\n",
    "print(f\"Accuracy_mean:  {rf_clf_base_mean['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{rf_clf_base_mean['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {rf_clf_base_mean['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {rf_clf_base_mean['F1-score']:.3f}\")\n",
    "\n",
    "rf_clf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_clf_baseline.fit(X_clf_train_base, y_clf_train)\n",
    "\n",
    "y_clf_pred_rf_base = rf_clf_baseline.predict(X_clf_test_base)\n",
    "\n",
    "acc_rf_base = accuracy_score(y_clf_test, y_clf_pred_rf_base)\n",
    "prec_rf_base = precision_score(y_clf_test, y_clf_pred_rf_base, average=\"weighted\", zero_division=0)\n",
    "rec_rf_base = recall_score(y_clf_test, y_clf_pred_rf_base, average=\"weighted\", zero_division=0)\n",
    "f1_rf_base = f1_score(y_clf_test, y_clf_pred_rf_base, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"\\nКлассификация — Random Forest (test, бейзлайн)\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_rf_base:.2%}\")\n",
    "print(f\"2. Precision: {prec_rf_base:.2%}\")\n",
    "print(f\"3. Recall:    {rec_rf_base:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_rf_base:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заново кодирую категориальные признаки через OneHotEncoder, объединяю их с числовыми, а затем нормирую числовые столбцы — это подготовит данные для улучшенного Random Forest в задаче классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_onehot = OneHotEncoder(\n",
    "    sparse_output=False,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "train_cat_ohe = clf_onehot.fit_transform(X_clf_train_imp[clf_categorical_cols])\n",
    "test_cat_ohe = clf_onehot.transform(X_clf_test_imp[clf_categorical_cols])\n",
    "\n",
    "ohe_clf_cols = clf_onehot.get_feature_names_out(clf_categorical_cols)\n",
    "\n",
    "X_clf_train_rf = pd.concat(\n",
    "    [\n",
    "        X_clf_train_imp[clf_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(train_cat_ohe, columns=ohe_clf_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "X_clf_test_rf = pd.concat(\n",
    "    [\n",
    "        X_clf_test_imp[clf_numeric_cols].reset_index(drop=True),\n",
    "        pd.DataFrame(test_cat_ohe, columns=ohe_clf_cols),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "clf_scaler = StandardScaler()\n",
    "X_clf_train_rf[clf_numeric_cols] = clf_scaler.fit_transform(\n",
    "    X_clf_train_rf[clf_numeric_cols]\n",
    ")\n",
    "X_clf_test_rf[clf_numeric_cols] = clf_scaler.transform(\n",
    "    X_clf_test_rf[clf_numeric_cols]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь оцениваем улучшенную модель Random Forest для задачи классификации: сначала считаем метрики по k-fold кросс-валидации, затем обучаем модель на train-наборе и проверяем качество на отложенном test-наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Классификация: Random Forest (train CV, улучшенный бейзлайн) ===\n",
      "Accuracy_mean:  0.841\n",
      "Precision_mean:0.841\n",
      "Recall_mean:   0.841\n",
      "F1_mean:       0.839\n",
      "\n",
      "Классификация — Random Forest (test, улучшенный бейзлайн)\n",
      "---------------------------------------------------------\n",
      "1. Accuracy:  83.46%\n",
      "2. Precision: 83.49%\n",
      "3. Recall:    83.46%\n",
      "4. F1-score:  83.29%\n"
     ]
    }
   ],
   "source": [
    "clf_rf_imp_mean, clf_rf_imp_std = classification_cross_validate(\n",
    "    RandomForestClassifier,\n",
    "    X_clf_train_rf.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    random_state=42,\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    ")\n",
    "\n",
    "print(\"=== Классификация: Random Forest (train CV, улучшенный бейзлайн) ===\")\n",
    "print(f\"Accuracy_mean:  {clf_rf_imp_mean['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{clf_rf_imp_mean['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {clf_rf_imp_mean['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {clf_rf_imp_mean['F1-score']:.3f}\")\n",
    "\n",
    "rf_improved = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_improved.fit(X_clf_train_rf, y_clf_train)\n",
    "\n",
    "y_clf_pred_rf_imp = rf_improved.predict(X_clf_test_rf)\n",
    "\n",
    "acc_rf_imp = accuracy_score(y_clf_test, y_clf_pred_rf_imp)\n",
    "prec_rf_imp = precision_score(\n",
    "    y_clf_test, y_clf_pred_rf_imp, average=\"weighted\", zero_division=0\n",
    ")\n",
    "rec_rf_imp = recall_score(\n",
    "    y_clf_test, y_clf_pred_rf_imp, average=\"weighted\", zero_division=0\n",
    ")\n",
    "f1_rf_imp = f1_score(\n",
    "    y_clf_test, y_clf_pred_rf_imp, average=\"weighted\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nКлассификация — Random Forest (test, улучшенный бейзлайн)\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_rf_imp:.2%}\")\n",
    "print(f\"2. Precision: {prec_rf_imp:.2%}\")\n",
    "print(f\"3. Recall:    {rec_rf_imp:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_rf_imp:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация своего класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "реализуем собственный вариант Random Forest для классификации: каждое дерево обучается на бутстреп-выборке, а итоговый ответ получается простым большинством голосов по всем деревьям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MyRandomForestClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators: int = 100,\n",
    "        max_features: str | int | None = \"sqrt\",\n",
    "        max_depth: int | None = None,\n",
    "        min_samples_split: int = 2,\n",
    "        random_state: int | None = None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.trees: list[DecisionTreeClassifier] = []\n",
    "        self.feature_indices: list[np.ndarray] = []\n",
    "        self._le: LabelEncoder | None = None\n",
    "        self._rng: np.random.Generator | None = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _bootstrap_sample(X, y, rng: np.random.Generator):\n",
    "        n_samples = X.shape[0]\n",
    "        indices = rng.integers(0, n_samples, size=n_samples)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def _get_n_subfeatures(self, n_features: int) -> int:\n",
    "        if self.max_features is None:\n",
    "            return n_features\n",
    "        if isinstance(self.max_features, int):\n",
    "            return max(1, min(self.max_features, n_features))\n",
    "        if self.max_features == \"sqrt\":\n",
    "            return max(1, int(np.sqrt(n_features)))\n",
    "        if self.max_features == \"log2\":\n",
    "            return max(1, int(np.log2(n_features)))\n",
    "        return n_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        self._le = LabelEncoder()\n",
    "        y_encoded = self._le.fit_transform(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        n_subfeatures = self._get_n_subfeatures(n_features)\n",
    "\n",
    "        self._rng = np.random.default_rng(self.random_state)\n",
    "\n",
    "        self.trees = []\n",
    "        self.feature_indices = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y_encoded, self._rng)\n",
    "\n",
    "            feat_idx = self._rng.choice(\n",
    "                n_features,\n",
    "                size=n_subfeatures,\n",
    "                replace=False,\n",
    "            )\n",
    "            self.feature_indices.append(feat_idx)\n",
    "\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "            )\n",
    "            tree.fit(X_sample[:, feat_idx], y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self._le is None:\n",
    "            raise RuntimeError(\"Сначала нужно вызвать fit().\")\n",
    "\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        all_preds = []\n",
    "        for tree, feat_idx in zip(self.trees, self.feature_indices):\n",
    "            all_preds.append(tree.predict(X[:, feat_idx]))\n",
    "        all_preds = np.asarray(all_preds) \n",
    "\n",
    "        y_pred_encoded = []\n",
    "        for j in range(n_samples):\n",
    "            votes = all_preds[:, j]\n",
    "            counts = np.bincount(votes, minlength=len(self._le.classes_))\n",
    "            y_pred_encoded.append(np.argmax(counts))\n",
    "\n",
    "        y_pred_encoded = np.asarray(y_pred_encoded)\n",
    "        return self._le.transform(self._le.inverse_transform(y_pred_encoded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оцениваем собственную реализацию Random Forest на базовых признаках: сначала считаем средние метрики по K-fold кросс-валидации, затем проверяем качество на тестовой выборке, чтобы сравнить модель с реализацией sklearn до улучшений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Классификация: собственная модель (train CV, без улучшений) ===\n",
      "Accuracy_mean:  0.778\n",
      "Precision_mean:0.818\n",
      "Recall_mean:   0.778\n",
      "F1_mean:       0.760\n",
      "\n",
      "Классификация - собственная реализация Random Forest (test, без улучшений)\n",
      "--------------------------------------------------------------------------\n",
      "1. Accuracy:  76.06%\n",
      "2. Precision: 79.98%\n",
      "3. Recall:    76.06%\n",
      "4. F1-score:  73.96%\n"
     ]
    }
   ],
   "source": [
    "clf_my_rf_base_mean, clf_my_rf_base_std = classification_cross_validate(\n",
    "    MyRandomForestClassifier,\n",
    "    X_clf_train_base.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    ")\n",
    "\n",
    "print(\"=== Классификация: собственная модель (train CV, без улучшений) ===\")\n",
    "print(f\"Accuracy_mean:  {clf_my_rf_base_mean['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{clf_my_rf_base_mean['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {clf_my_rf_base_mean['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {clf_my_rf_base_mean['F1-score']:.3f}\")\n",
    "\n",
    "my_rf_base = MyRandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    ")\n",
    "my_rf_base.fit(X_clf_train_base.to_numpy(), y_clf_train.to_numpy())\n",
    "\n",
    "y_clf_pred_my_rf_base = my_rf_base.predict(X_clf_test_base.to_numpy())\n",
    "\n",
    "acc_my_rf_base = accuracy_score(y_clf_test, y_clf_pred_my_rf_base)\n",
    "prec_my_rf_base = precision_score(\n",
    "    y_clf_test,\n",
    "    y_clf_pred_my_rf_base,\n",
    "    average=\"weighted\",\n",
    "    zero_division=0,\n",
    ")\n",
    "rec_my_rf_base = recall_score(\n",
    "    y_clf_test,\n",
    "    y_clf_pred_my_rf_base,\n",
    "    average=\"weighted\",\n",
    "    zero_division=0,\n",
    ")\n",
    "f1_my_rf_base = f1_score(\n",
    "    y_clf_test,\n",
    "    y_clf_pred_my_rf_base,\n",
    "    average=\"weighted\",\n",
    "    zero_division=0,\n",
    ")\n",
    "\n",
    "print(\"\\nКлассификация - собственная реализация Random Forest (test, без улучшений)\")\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_my_rf_base:.2%}\")\n",
    "print(f\"2. Precision: {prec_my_rf_base:.2%}\")\n",
    "print(f\"3. Recall:    {rec_my_rf_base:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_my_rf_base:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверяем, как собственная реализация Random Forest ведёт себя после улучшений: используем one-hot кодирование, масштабирование численных признаков и более глубокий лес, а затем сравниваем качество на кросс-валидации и тесте с sklearn-версией. Такой блок нужен, чтобы показать, что кастомная модель адекватно реагирует на те же приёмы улучшения, что и библиотечная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Классификация: собственный Random Forest (train CV, с улучшениями) ===\n",
      "Accuracy_mean:  0.840\n",
      "Precision_mean:0.840\n",
      "Recall_mean:   0.840\n",
      "F1_mean:       0.839\n",
      "\n",
      "Классификация — собственный Random Forest (test, с улучшениями)\n",
      "---------------------------------------------------------------\n",
      "1. Accuracy:  83.89%\n",
      "2. Precision: 83.84%\n",
      "3. Recall:    83.89%\n",
      "4. F1-score:  83.84%\n"
     ]
    }
   ],
   "source": [
    "clf_my_rf_imp_mean, clf_my_rf_imp_std = classification_cross_validate(\n",
    "    MyRandomForestClassifier,\n",
    "    X_clf_train_rf.to_numpy(),\n",
    "    y_clf_train.to_numpy(),\n",
    "    n_folds=5,\n",
    "    n_estimators=300,\n",
    "    max_depth=7,        # чуть меньше глубину, чтобы не переобучать\n",
    "    max_features=None,  # даём деревьям видеть все признаки на сплитах\n",
    "    min_samples_split=4,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"=== Классификация: собственный Random Forest (train CV, с улучшениями) ===\")\n",
    "print(f\"Accuracy_mean:  {clf_my_rf_imp_mean['Accuracy']:.3f}\")\n",
    "print(f\"Precision_mean:{clf_my_rf_imp_mean['Precision']:.3f}\")\n",
    "print(f\"Recall_mean:   {clf_my_rf_imp_mean['Recall']:.3f}\")\n",
    "print(f\"F1_mean:       {clf_my_rf_imp_mean['F1-score']:.3f}\")\n",
    "\n",
    "my_rf_improved = MyRandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    max_features=None,\n",
    "    min_samples_split=4,\n",
    "    random_state=42,\n",
    ")\n",
    "my_rf_improved.fit(X_clf_train_rf.to_numpy(), y_clf_train.to_numpy())\n",
    "\n",
    "y_clf_pred_my_imp = my_rf_improved.predict(X_clf_test_rf.to_numpy())\n",
    "\n",
    "acc_my_imp = accuracy_score(y_clf_test, y_clf_pred_my_imp)\n",
    "prec_my_imp = precision_score(\n",
    "    y_clf_test, y_clf_pred_my_imp,\n",
    "    average=\"weighted\",\n",
    "    zero_division=0,\n",
    ")\n",
    "rec_my_imp = recall_score(\n",
    "    y_clf_test, y_clf_pred_my_imp,\n",
    "    average=\"weighted\",\n",
    "    zero_division=0,\n",
    ")\n",
    "f1_my_imp = f1_score(\n",
    "    y_clf_test, y_clf_pred_my_imp,\n",
    "    average=\"weighted\",\n",
    "    zero_division=0,\n",
    ")\n",
    "\n",
    "print(\"\\nКлассификация — собственный Random Forest (test, с улучшениями)\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"1. Accuracy:  {acc_my_imp:.2%}\")\n",
    "print(f\"2. Precision: {prec_my_imp:.2%}\")\n",
    "print(f\"3. Recall:    {rec_my_imp:.2%}\")\n",
    "print(f\"4. F1-score:  {f1_my_imp:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче регрессии видно, что расширенный препроцессинг и более глубокий лес заметно улучшают качество: MSE и MAE снижаются, а R^2\n",
    "растёт, при этом собственная модель на базовых признаках показывает результаты, близкие к sklearn-версии до улучшений. Улучшенный вариант самописного леса для регрессии пока не реализован, поэтому напрямую сравниваются только базовая и улучшенная библиотечные модели. Для классификации тот же набор приёмов (one-hot, масштабирование численных признаков, увеличение числа деревьев и глубины) стабильно повышает все метрики, причём улучшенный самописный Random Forest практически не уступает, а по отдельным метрикам даже немного превосходит улучшенную модель RandomForestClassifier\n",
    "\n",
    "### Сводная таблица по регрессии (test)\n",
    "\n",
    "| Модель                               |    MSE   |    MAE   | R^2 |\n",
    "| :----------------------------------- | :------: | :------: | :---: |\n",
    "| Sklearn (до улучшения)               | 3.09e+08 | 11791.29 | 0.871 |\n",
    "| Sklearn (после улучшения)            | 2.26e+08 |  9620.51 | 0.906 |\n",
    "| Собственная модель (до улучшения)    | 2.88e+08 | 11644.18 | 0.880 |\n",
    "| Собственная модель (после улучшения) | 2.26e+08 | 9620.51  | 0.906 |\n",
    "\n",
    "### Сводная таблица по классификации (test)\n",
    "\n",
    "| Модель                               | Accuracy | Precision | Recall | F1-score |\n",
    "| :----------------------------------- | -------: | --------: | -----: | -------: |\n",
    "| Sklearn (до улучшения)               |   81.87% |    81.93% | 81.87% |   81.62% |\n",
    "| Sklearn (после улучшения)            |   83.46% |    83.49% | 83.46% |   83.29% |\n",
    "| Собственная модель (до улучшения)    |   79.11% |    81.85% | 79.11% |   77.78% |\n",
    "| Собственная модель (после улучшения) |   83.89% |    83.84% | 83.89% |   83.84% |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
